"""
Real TextWorld Benchmark

This script validates the Perceptual Layer on a REAL TextWorld game generated by the adapter.
It proves that the agent can:
1. Interface with the real TextWorld engine.
2. Parse complex, generated natural language using LLMPerception.
3. Make decisions based on the structured state.

Dependencies:
- Neo4j (for TextWorldAdapter)
- TextWorld (installed in env)
- LLMPerception (our new module)
"""

import sys
import os
import random
import time
from neo4j import GraphDatabase

# Add project root to path
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

import config
from environments.domain4_textworld.textworld_adapter import TextWorldAdapter
from perception.llm_parser import LLMPerception
from planning.simple_graph_planner import GraphPlanner
from memory.episodic_replay import EpisodicMemory

class RealTextWorldAgent:
    def __init__(self, planner: GraphPlanner = None):
        self.perception = LLMPerception(model_name="gpt-4o-mini")
        self.planner = planner
        
    def act(self, observation, admissible_commands):
        """
        Decide action based on LLM perception of the observation.
        """
        # 1. Perceive
        print(f"\n[Perception] Reading observation...")
        # We only parse the description part usually, but here we pass the whole feedback
        state = self.perception.parse(observation)
        print(f"[Perception] Extracted: {state}")
        
        # 2. Heuristic Logic (The "Brain")
        # Goal: Explore and interact
        
        # Priority 1: Take useful items
        items = state.get("items", [])
        for item in items:
            name = item["name"].lower()
            if item.get("location") != "inventory":
                take_cmd = f"take {name}"
                if take_cmd in admissible_commands:
                    return take_cmd
        
        # Priority 2: Open closed doors/containers
        for item in items:
            if item.get("state") == "closed":
                name = item["name"].lower()
                open_cmd = f"open {name}"
                if open_cmd in admissible_commands:
                    return open_cmd
        
        # Priority 3: Use planner to move towards an exit if possible
        if self.planner and state.get("room_name"):
            plan = self.planner.plan_to_exit(state["room_name"])
            if plan:
                # take the first direction from the plan
                direction = plan[0]
                go_cmd = f"go {direction}"
                if go_cmd in admissible_commands:
                    return go_cmd
        
        # Priority 4: Fallback to any go command
        go_commands = [c for c in admissible_commands if c.startswith("go ")]
        if go_commands:
            return random.choice(go_commands)
        
        # Priority 5: Random valid action (fallback)
        return random.choice(admissible_commands)

def run_benchmark():
    print("\n" + "="*70)
    print("üöÄ REAL TEXTWORLD BENCHMARK (LLM Perception)")
    print("="*70)
    
    # Setup Neo4j
    driver = GraphDatabase.driver(
        config.NEO4J_URI,
        auth=(config.NEO4J_USER, config.NEO4J_PASSWORD)
    )
    session = driver.session(database="neo4j")
    # Instantiate planner
    planner = GraphPlanner(session)
    # Episodic memory instance (if enabled)
    episodic_mem = EpisodicMemory(session) if config.ENABLE_EPISODIC_MEMORY else None
    
    try:
        # 1. Setup Environment
        print("\n1. Setting up TextWorld Adapter...")
        adapter = TextWorldAdapter(session)
        
        # Generate a simple game (Seed 42 is usually a kitchen/house scenario)
        print("   Generating game (Seed=42)...")
        adapter.generate_game(seed=42)
        
        # Reset
        print("   Resetting environment...")
        initial_state = adapter.reset()
        
        # 2. Setup Agent
        print("\n2. Initializing Agent with LLM Perception...")
        agent = RealTextWorldAgent(planner=planner)
        
        # 3. Run Episode
        print("\n3. Starting Episode...")
        obs = initial_state.feedback
        done = False
        total_reward = 0
        visited_rooms = []
        
        for i in range(15): # Run for 15 steps
            print(f"\n--- Step {i+1} ---")
            print(f"[Game Output] {obs.strip()[:200]}...") # Truncate for display
            
            # Get valid commands for safety/heuristic
            admissible = adapter.get_admissible_commands()
            print(f"[Valid Cmds] {admissible[:5]}...")
            
            # Agent Act
            action = agent.act(obs, admissible)
            print(f"[Action] {action}")
            
            # Env Step
            next_state, reward, done = adapter.step(action)
            obs = next_state.feedback
            total_reward += reward
            
            # Record visited room from perception
            try:
                state = agent.perception.parse(obs)
                if state.get("room_name"):
                    visited_rooms.append(state["room_name"])
            except Exception:
                pass
            
            if reward > 0:
                print(f"üéâ REWARD: {reward}")
            
            if done:
                print("\nüèÜ GAME WON!")
                break
                
        print(f"\nTotal Reward: {total_reward}")
        
        # Store episodic memory if enabled
        if episodic_mem is not None:
            episode_id = f"real_{int(time.time())}"
            actual_path = {
                "path_id": f"actual_{episode_id}",
                "outcome": "success" if total_reward > 0 else "failure",
                "steps": i+1,
                "final_distance": 0 if total_reward > 0 else 999,
                "rooms_visited": visited_rooms,
                "actions_taken": []
            }
            episodic_mem.store_actual_path(episode_id, actual_path)

        
        if total_reward > 0 or i > 5:
            print("\n‚úÖ BENCHMARK PASSED: Agent successfully interacted with real TextWorld.")
        else:
            print("\n‚ö†Ô∏è BENCHMARK INCONCLUSIVE: No reward, but maybe just hard game.")
            
    except Exception as e:
        print(f"\n‚ùå ERROR: {e}")
        import traceback
        traceback.print_exc()
    finally:
        if 'adapter' in locals():
            adapter.close()
        session.close()
        driver.close()

if __name__ == "__main__":
    run_benchmark()
